{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my GPT WebApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.1.2)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/torchvision-0.2.0-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.0+cpu (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.0+cpu\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.0.350)\n",
      "Requirement already satisfied: einops in /opt/homebrew/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/lib/python3.11/site-packages (0.25.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.36.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/homebrew/lib/python3.11/site-packages (0.41.3.post2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.3)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.1)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.71)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/michaelchen/Library/Python/3.11/lib/python/site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/homebrew/lib/python3.11/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.11/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade\n",
    "!pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install langchain einops accelerate transformers bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is cuda is available\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model-00001-of-00009.bin: 100%|██████████| 9.50G/9.50G [07:22<00:00, 21.5MB/s]\n",
      "pytorch_model-00002-of-00009.bin: 100%|██████████| 9.51G/9.51G [06:15<00:00, 25.3MB/s]\n",
      "pytorch_model-00003-of-00009.bin: 100%|██████████| 9.51G/9.51G [05:46<00:00, 27.5MB/s]\n",
      "pytorch_model-00004-of-00009.bin: 100%|██████████| 9.51G/9.51G [07:20<00:00, 21.6MB/s]\n",
      "pytorch_model-00005-of-00009.bin: 100%|██████████| 9.51G/9.51G [08:42<00:00, 18.2MB/s]\n",
      "pytorch_model-00006-of-00009.bin: 100%|██████████| 9.51G/9.51G [08:03<00:00, 19.7MB/s]\n",
      "pytorch_model-00007-of-00009.bin: 100%|██████████| 9.51G/9.51G [09:20<00:00, 17.0MB/s]\n",
      "pytorch_model-00008-of-00009.bin: 100%|██████████| 9.51G/9.51G [07:44<00:00, 20.5MB/s]\n",
      "pytorch_model-00009-of-00009.bin: 100%|██████████| 7.58G/7.58G [04:53<00:00, 25.8MB/s]\n",
      "Downloading shards: 100%|██████████| 9/9 [1:05:35<00:00, 437.32s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/9 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BFloat16 is not supported on MPS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the model with specified configurations\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./workspace/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moffload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Prepare the model for inference\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mregister(config\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, model_class, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/modeling_utils.py:3694\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3685\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3686\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3687\u001b[0m     (\n\u001b[1;32m   3688\u001b[0m         model,\n\u001b[1;32m   3689\u001b[0m         missing_keys,\n\u001b[1;32m   3690\u001b[0m         unexpected_keys,\n\u001b[1;32m   3691\u001b[0m         mismatched_keys,\n\u001b[1;32m   3692\u001b[0m         offload_index,\n\u001b[1;32m   3693\u001b[0m         error_msgs,\n\u001b[0;32m-> 3694\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   3695\u001b[0m         model,\n\u001b[1;32m   3696\u001b[0m         state_dict,\n\u001b[1;32m   3697\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3698\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3699\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3700\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   3701\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   3702\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   3703\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   3704\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3705\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3706\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   3707\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   3708\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(\u001b[39mgetattr\u001b[39;49m(model, \u001b[39m\"\u001b[39;49m\u001b[39mquantization_method\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39m==\u001b[39;49m QuantizationMethod\u001b[39m.\u001b[39;49mBITS_AND_BYTES),\n\u001b[1;32m   3709\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3710\u001b[0m     )\n\u001b[1;32m   3712\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   3713\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/modeling_utils.py:4104\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4100\u001b[0m                     set_module_quantized_tensor_to_device(\n\u001b[1;32m   4101\u001b[0m                         model_to_load, key, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mempty(\u001b[39m*\u001b[39mparam\u001b[39m.\u001b[39msize(), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   4102\u001b[0m                     )\n\u001b[1;32m   4103\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4104\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[39m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[1;32m   4105\u001b[0m             model_to_load,\n\u001b[1;32m   4106\u001b[0m             state_dict,\n\u001b[1;32m   4107\u001b[0m             loaded_keys,\n\u001b[1;32m   4108\u001b[0m             start_prefix,\n\u001b[1;32m   4109\u001b[0m             expected_keys,\n\u001b[1;32m   4110\u001b[0m             device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   4111\u001b[0m             offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   4112\u001b[0m             offload_index\u001b[39m=\u001b[39;49moffload_index,\n\u001b[1;32m   4113\u001b[0m             state_dict_folder\u001b[39m=\u001b[39;49mstate_dict_folder,\n\u001b[1;32m   4114\u001b[0m             state_dict_index\u001b[39m=\u001b[39;49mstate_dict_index,\n\u001b[1;32m   4115\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   4116\u001b[0m             is_quantized\u001b[39m=\u001b[39;49mis_quantized,\n\u001b[1;32m   4117\u001b[0m             is_safetensors\u001b[39m=\u001b[39;49mis_safetensors,\n\u001b[1;32m   4118\u001b[0m             keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   4119\u001b[0m         )\n\u001b[1;32m   4120\u001b[0m         error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_error_msgs\n\u001b[1;32m   4121\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/modeling_utils.py:778\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    775\u001b[0m     state_dict_index \u001b[39m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    776\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_quantized:\n\u001b[1;32m    777\u001b[0m     \u001b[39m# For backward compatibility with older versions of `accelerate`\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mset_module_kwargs)\n\u001b[1;32m    779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mint8 \u001b[39mand\u001b[39;00m param_name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSCB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39min\u001b[39;00m state_dict\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/accelerate/utils/modeling.py:317\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    315\u001b[0m             module\u001b[39m.\u001b[39m_parameters[tensor_name] \u001b[39m=\u001b[39m param_cls(new_value, requires_grad\u001b[39m=\u001b[39mold_value\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 317\u001b[0m     new_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     new_value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(value, device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: BFloat16 is not supported on MPS"
     ]
    }
   ],
   "source": [
    "# Identifier for the model to be loaded\n",
    "model_id = \"tiiuae/falcon-40b-instruct\"\n",
    "\n",
    "# Initialize tokenizer from Hugging Face's transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Load the model with specified configurations\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    cache_dir='./workspace/', \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    trust_remote_code=True, \n",
    "    device_map='auto', \n",
    "    offload_folder='offload'\n",
    ")\n",
    "\n",
    "# Prepare the model for inference\n",
    "model.eval()\n",
    "\n",
    "# Setup the pipeline for text generation\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    max_length=400,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('Who is Kim Kardasian?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
